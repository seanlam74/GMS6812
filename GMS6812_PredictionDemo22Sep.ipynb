{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "GMS6812_PredictionDemo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanlam74/GMS6812/blob/master/GMS6812_PredictionDemo22Sep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF6UM5ETe421",
        "colab_type": "text"
      },
      "source": [
        "# GMS6812 Predictive Modeling Demo for Healthcare Analytics\n",
        "\n",
        "#### Instructor: Sean Lam (Email: lam.shao.wei@singhealth.com.sg), Health Services Research, SingHealth and Duke NUS\n",
        "\n",
        "In this demo, you will learn the following,\n",
        "- Performed Explanatory Data Analysis and applied extensive feature engineering, feature selection and on Diabetes patient’s hospital readmission data.\n",
        "- Built Decision Tree and Logistic classifiers in python using Scikit-Learn to predict which patients might be readmitted to the hospital."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxIfuS-Ve422",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import chisquare, ks_2samp\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OldJTsciQz1b",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ0P5XnWiaSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the data into python with \"pandas\", file in GItHub\n",
        "url = 'https://github.com/seanlam74/GMS6812/blob/master/training_data.csv'\n",
        "df = pd.read_csv(url, error_bad_lines=False)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtI3zdkKe425",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the data into python with \"pandas\"\n",
        "data=pd.read_csv('training_data.csv',header=0,skiprows=0,engine='python')\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YetH8b7ze42_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# printing out first 5 observations\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZlLaAzHe43B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Printing all the columns in the dataset\n",
        "print(data.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BkP-y7TTe43E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Descriptive statistics of all the rows\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "print(data.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuXX_bPBQ6vQ",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9KriL2CQ_Ql",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Data Quality Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ihVqV4e43H",
        "colab_type": "text"
      },
      "source": [
        "Before we do analysis we need to make sure that there are no duplicate rows.<br> \n",
        "By looking at the data we can confirm that encounter_id is unique and we are checking if there are any duplicate encounter_ids and we find that there aren't any."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeWjf2H3e43I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = data['encounter_id']\n",
        "data[ids.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w14_qUVQe43L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking if there are any duplicates in encounter_id - no duplicates found\n",
        "ids = data['encounter_id']\n",
        "data[ids.isin(ids[ids.duplicated()])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0NSNW3_e43O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove duplicates and check again\n",
        "data = data.drop_duplicates()\n",
        "data[ids.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvdDP7_me43R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Considering values with '?' as missing values.\n",
        "data = data.replace('?', np.NaN )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x9LZBiae43T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Two observation is unknown in gender. Replace it as a null value\n",
        "print('gender', data['gender'][data['gender'] == 'Unknown/Invalid'].count())\n",
        "data = data.replace('Unknown/Invalid', np.NaN )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9kT9Kf5le43W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding the number of null values in each column\n",
        "print(data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGYCnLr2e43Z",
        "colab_type": "text"
      },
      "source": [
        "Any row that has more than 40% missing values is rejected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb6pv3n4e43Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Weight has almost 99% of missing data ; Payer_code and medical_speciality has around 45% of missing data. \n",
        "data.drop(['weight','payer_code','medical_specialty','diag_2', 'diag_3'],axis=1,inplace=True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vQH8t6We43b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropping rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "c3r4vVX3e43e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[0:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFKoLVYte43h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a list of categorical and numeric columns names\n",
        "categorical=data.select_dtypes(include=['object']) # select strings\n",
        "numeric=data.select_dtypes(exclude=['object'])\n",
        "print(categorical.columns.values)\n",
        "print(numeric.columns.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5-fBLeMDe43j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# printing the frequency count of all the categorical features\n",
        "for col in categorical:\n",
        "    print(categorical[col].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AB0DKm6Te43m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# printing the frequency of all the numeric features\n",
        "for col in numeric:\n",
        "    print(numeric[col].value_counts())\n",
        "# Didn't find any outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "QgmZtY4fe43p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in categorical:\n",
        "    categorical[col].value_counts().plot(kind='bar')\n",
        "    plt.show()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o7Vnerve43r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data['max_glu_serum'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WZ1XmfaVe43u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in numeric:\n",
        "    numeric[col].plot.hist(bins=6)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB-KLaeHe43w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleting the 2 columns because they have all the observations only in one category \n",
        "data.drop(['examide','citoglipton'],axis=1,inplace=True) # axis=1 column\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jajV_SXie43z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making the target variable and other variables binary\n",
        "data = data[data['readmitted'].isin(['Y', 'N'])] # keep those with Y/N\n",
        "data['readmitted'] = data['readmitted'].apply(lambda x: 0 if x == \"N\" else 1)\n",
        "data['change'] = data['change'].apply(lambda x: 0 if x == \"No\" else 1)\n",
        "data['gender'] = data['gender'].apply(lambda x: 0 if x == \"Female\" else 1)\n",
        "data['diabetesMed'] = data['diabetesMed'].apply(lambda x: 0 if x == \"No\" else 1)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkyqjNPe431",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are 3 types of visits to a hospital. 1) Inpatient 2) Outpatient 3) Emergency.\n",
        "# Combining them into a single column\n",
        "data['total_visits'] = data['number_outpatient'] + data['number_emergency'] + data['number_inpatient']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTjVDWM4e433",
        "colab_type": "text"
      },
      "source": [
        "We have age feature which is given in bins. We have to changed it with the average value. eg: for age 0-10 we took the average age which is 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbHi2go8e433",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining a function to give average value for the age\n",
        "def agecategory(x):\n",
        "    \n",
        "    if x == \"[0-10)\" :\n",
        "        return 5\n",
        "    elif x == \"[10-20)\":\n",
        "        return 15\n",
        "    elif x == \"[20-30)\":\n",
        "        return 25\n",
        "    elif x == \"[30-40)\":\n",
        "        return 35\n",
        "    elif x == \"[40-50)\":\n",
        "        return 45\n",
        "    elif x == \"[50-60)\":\n",
        "        return 55\n",
        "    elif x == \"[60-70)\":\n",
        "        return 65\n",
        "    elif x == \"[70-80)\":\n",
        "        return 75\n",
        "    else:\n",
        "        return 0        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmb8Cwrbe436",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replacing the age bins with their average value\n",
        "data['age'] = data['age'].apply(lambda x: agecategory(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCifG3oe43-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['age'][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXCL7iwGe44A",
        "colab_type": "text"
      },
      "source": [
        "There are 23 treatments of which 2 treatments are never used by patients and we took the number of treatments the patient has undergone as a feature which will be used for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_-McfRQe44B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are many treatments from which a doctor would recommend the patient, lets combine all the treatments into one dataframe\n",
        "treatments = ['metformin' ,'repaglinide','nateglinide','chlorpropamide','glimepiride','acetohexamide' ,'glipizide',\\\n",
        "              'glyburide', 'tolbutamide', 'pioglitazone','rosiglitazone', 'acarbose' ,'miglitol' ,'troglitazone', \\\n",
        "              'tolazamide', 'insulin' ,'glyburide-metformin','glipizide-metformin', \\\n",
        "              'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SgdkNY6fe44D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(treatments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b73YTfvne44F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assigning a value of 0 if there are not undergoing treatment and assigning 1 even if they are taking\\\n",
        "# increasing/decreasing/steady dosage\n",
        "for i in treatments:\n",
        "    data[i] = data[i].apply(lambda x: 0 if x == \"No\" else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjBv-H6Pe44H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding out total number of treatments taken by patient\n",
        "data['treatments_taken'] = np.zeros((len(data['metformin']))) # create zero-vector of all rows\n",
        "for col in treatments:\n",
        "    data['treatments_taken'] += data[col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDE0FFade44K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftvpsa3ke44M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A1C > 6.4 implies that the patient has diabetes. Therefore, considered values greater than 7 and 8 together.\n",
        "# other 2 categories : Norm and None ; Norm implies the values in the normal range ; None implies no test conducted;\n",
        "data['A1Cresult'] = data['A1Cresult'].apply(lambda x: 0 if x == \"None\" else (1 if x==\"Norm\" else 2) )\n",
        "data['max_glu_serum'] = data['max_glu_serum'].apply(lambda x: 0 if x == \"None\" else (1 if x==\"Norm\" else 2) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptYtxmMme44O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Based on information in https://www.hindawi.com/journals/bmri/2014/781670/tab2/.Classified diagnosis into 9 categories\n",
        "#Categories[0-8]: Other,Circulatory, Respiratory,Digestive, Diabetes,Injury, Musculoskeletal,Genitourinary,Neoplasms\n",
        "#defining the function to classify the numbers into one of the 8 categories\n",
        "\n",
        "def getCategor(x):\n",
        "    if 'V' in str(x) or 'E' in str(x):\n",
        "        return 0\n",
        "    \n",
        "    x = float(x)\n",
        "    \n",
        "    if (x >= 390 and x <= 459) or np.floor(x) == 785:\n",
        "        return 1\n",
        "    elif (x >= 460 and x <= 519) or np.floor(x) == 786:\n",
        "        return 2\n",
        "    elif (x >= 520 and x <= 579) or np.floor(x) == 787:\n",
        "        return 3\n",
        "    elif np.floor(x) == 250:\n",
        "        return 4\n",
        "    elif x >= 800 and x <= 999:\n",
        "        return 5\n",
        "    elif x >= 710 and x <= 739:\n",
        "        return 6\n",
        "    elif (x >= 580 and x <= 629) or np.floor(x) == 788:\n",
        "        return 7\n",
        "    elif x >= 140 and x <= 239:\n",
        "        return 8\n",
        "    else:\n",
        "        return 0\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FdqKe1me44Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#changing the values into categories\n",
        "data['diag_1_category'] = data['diag_1'].apply(lambda x: getCategor(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbFwbh7Qe44R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['diag_1_category'][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me6Zu8eBe44U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzMGEQD3e44V",
        "colab_type": "text"
      },
      "source": [
        "Some patients in the data have more than one encounters, we need to make sure to remove the multiple patient visits because that might cause bias in our predictions. For that reason we remove all the visits by a patient other than their first visit (i.e., index visit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TiFzR-Wze44W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for readmitted patients and remove all visits other than the 1st visit\n",
        "#patients = data['patient_nbr']\n",
        "#data[patients.isin(patients[patients.duplicated()])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhO0Tx-ge44Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping the patients encounters other than 1st visit\n",
        "data = data.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZOJ3x1Ze44Z",
        "colab_type": "text"
      },
      "source": [
        "Variables like admission_type_id, discharge_despotion_id etc does not have any intrinsic value associated with them. So we make them categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UJ6Xuxue44Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coercing the admission_type_id, discharge_disposition_id, admission_source_id diag_1_category, \\\n",
        "# max_glu_serum, A1Cresult into categorical since the magnitudes does not have any intrinsic value\n",
        "data['admission_type_id'] = data['admission_type_id'].astype('object')\n",
        "data['admission_source_id'] = data['admission_source_id'].astype('object')\n",
        "data['discharge_disposition_id'] = data['discharge_disposition_id'].astype('object')\n",
        "data['diag_1_category'] = data['diag_1_category'].astype('object')\n",
        "data['max_glu_serum'] = data['max_glu_serum'].astype('object')\n",
        "data['A1Cresult'] = data['A1Cresult'].astype('object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhTkYoLWe44c",
        "colab_type": "text"
      },
      "source": [
        "Features like encounter_id, patient_nbr are for identity purpose and do not contribute towards predictions, so we remove them from analysis. Variables like number_outpatient, number_emergency are being used to create new variable which are being used for analysis. So we can remove other unnecessary variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6MzOsQ8e44c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkC-izp8e44f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a list for unnecessary columns\n",
        "delete_columns = ['encounter_id','patient_nbr','number_outpatient','number_emergency','number_inpatient',\\\n",
        "                 'metformin','repaglinide','nateglinide','chlorpropamide','glimepiride','acetohexamide','glipizide'\\\n",
        "                  ,'glyburide','tolbutamide','pioglitazone','rosiglitazone','acarbose','miglitol','troglitazone' \\\n",
        "                  ,'tolazamide','insulin','glyburide-metformin','glipizide-metformin','glimepiride-pioglitazone',\\\n",
        "                  'metformin-rosiglitazone','metformin-pioglitazone','diag_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvRkyM57e44h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping the unnecessary columns\n",
        "data.drop(delete_columns, inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IglRtgPme44k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljZC-DsEe44l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import numpy as np\n",
        "#import seaborn as sns\n",
        "#%matplotlib inline\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import skew\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcFx7YX-e44p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a list of categorical and numeric lists\n",
        "categorical=data.select_dtypes(include=['object'])\n",
        "numeric=data.select_dtypes(exclude=['object'])\n",
        "print(categorical.columns.values)\n",
        "print(numeric.columns.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0njNIW8Ie44s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating dummies for all the categorical variables and deleting the original columns\n",
        "nominal_columns = ['race', 'admission_type_id', 'discharge_disposition_id','admission_source_id' ,'diag_1_category'\\\n",
        "                  , 'max_glu_serum', 'A1Cresult']\n",
        "dummy_df = pd.get_dummies(data[nominal_columns])\n",
        "data = pd.concat([data, dummy_df], axis=1)\n",
        "data = data.drop(nominal_columns, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsdwxZ_-e44v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "EOjgmjYMe44x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfhrIicte44z",
        "colab_type": "text"
      },
      "source": [
        "## Prepare training/test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h4CL5ive44z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhew6x55e442",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyx6HrgGe445",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data1['readmitted']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8jUemN3e449",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data1.drop('readmitted',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Lk8-AJe44_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXWAn22xe45C",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J8hv52Pe45C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op-SOK4Ze45D",
        "colab_type": "text"
      },
      "source": [
        "Precision (also called positive predictive value) \\\n",
        "Recall (also known as sensitivity) \\\n",
        "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZRNOFZZe45E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#performance = []\n",
        "#for max_depth in [2,3,5,7,10]:\n",
        "#    dTree = DecisionTreeClassifier(criterion='entropy', class_weight = \"balanced\", max_depth=max_depth)\n",
        "#    performance.append((max_depth, np.mean(cross_val_score(dTree, X_train, Y_train, cv = 10, scoring = \"f1_micro\"))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "xGyc9Kfle45H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(performance)\n",
        "#print(\"The best tree size is: \") \n",
        "#str(sorted(performance, key = lambda x: x[1])[-1][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VuhRac_Ke45L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5O_l_7SQe45O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "dTree = DecisionTreeClassifier(criterion='entropy', class_weight='balanced', max_depth = 5)\n",
        "#kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "dTree.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "y_prediction = dTree.predict(X_test)\n",
        "print(classification_report(Y_test, y_prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI3jc4Gxe45R",
        "colab_type": "text"
      },
      "source": [
        "Note that in binary classification, recall of the positive class is also known as “sensitivity”; recall of the negative class is “specificity”.\n",
        "\\\n",
        "Note: Cut-off values determine sensitivity, specificity, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEDtgZUAe45R",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxqzlslre45R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler() # Scaled data has zero mean and unit variance\n",
        "X_train_normal = scaler.fit_transform(X_train)\n",
        "X_test_normal = scaler.transform(X_test)\n",
        "\n",
        "#model = LogisticRegressionCV(Cs = 10, cv = 10, class_weight = \"balanced\")\n",
        "model = LogisticRegression(class_weight = \"balanced\")\n",
        "model.fit(X_train_normal, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrkKkY5xe45T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prediction = model.predict(X_test_normal)\n",
        "print(classification_report(y_prediction, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIo8xsdUe45V",
        "colab_type": "text"
      },
      "source": [
        "## Homework (unofficial)\n",
        "\n",
        "### 1) To explore result reporting with the predicted probabilities\n",
        "- ROC analysis, to report AUC value, sensitivity, specificity, positive predictive value, negative predictive value\n",
        "- Plot precision-recall curve, etc\n",
        "\n",
        "### 2) To build model with training dataset and validate it with (separate) test dataset\n",
        "- Use the \"test_data.csv\"\n",
        "\n",
        "### 3) To try different prediction methods\n",
        "- Random forest\n",
        "- XGBoost\n",
        "\n",
        "\n",
        "## Reference\n",
        "https://github.com/andrewwlong/diabetes_readmission"
      ]
    }
  ]
}